[[inputs.influxdb_v2_listener]]
service_address = "127.0.0.1:8186"
token = "${INFLUX_TOKEN}"

[[inputs.exec]]
    commands = ["awk -F. '{print $1}' /proc/uptime" ]
    name_override = "dwstats_uptime"
    data_format = "value"
    data_type = "integer"

# parse csv files generated by direwolf using its LOGFILE directive or
# related command line options. Note that these are not the raw logs
# displayed in direwolf's output; they are the CSV representation of the
# parsed packets that direwolf has received.
[[inputs.tail]]
  files = ["/var/log/direwolf/direwolf.log"]
  name_override = "aprs_packets"
  from_beginning = false
  pipe = false
  data_format = "csv"
  csv_header_row_count = 1
  csv_column_names = [ "chan","utime","isotime","source","heard","level","error","dti","name","symbol","latitude","longitude","speed","course","altitude","frequency","offset","tone","system","status","telemetry","comment" ]
  #fielddrop =        [                "isotime","source","heard","level","error","dti",       "symbol",                       "speed","course","altitude","frequency","offset","tone","system","status","telemetry","comment" ]
  csv_column_types = [ "int", "int", "string", "string", "string", "string", "int", "string", "string", "string", "float", "float", "string", "string", "string", "string", "string", "string", "string", "string", "string", "string"]
#  #csv_tag_columns = ["source","heard","name","latitude","longitude"]
  csv_tag_columns = ["name","source","heard"]
  csv_timestamp_column = "utime"
  csv_timestamp_format = "unix"
  csv_skip_errors = true
  [inputs.tail.tags]
    metric_type = "aprs_packets"
    log_source = "direwolf"

[[outputs.http]]
  url = "https://{{ logforwarding.collector.host }}/insert/jsonline?_msg_field=fields.comment&_time_field=timestamp,_stream_fields=tags.log_source,tags.host,tags.path"
  data_format = "json"
  namepass = ["aprs_packets"]
  use_batch_format = false
  [outputs.http.headers]
  Content-Type = "application/json"
  Authorization = "Bearer ${LOGS_TOKEN}"

# Configuration for sending metrics to InfluxDB 2.0
[[outputs.influxdb_v2]]
  urls =  ["https://{{ metrics.host }}"]
  organization = "{{ metrics.org }}"
  bucket = "{{ metrics.bucket }}"
  token = "${INFLUX_TOKEN}"
  namedrop = ["aprs_positions","cpu","disk","diskio","kernel","mem","processes","swap","system"]
  #ping_timeout = "15s"
  #read_idle_timeout = "30s"
#   ## The URLs of the InfluxDB cluster nodes.
#   ##
#   ## Multiple URLs can be specified for a single cluster, only ONE of the
#   ## urls will be written to each interval.
#   ##   ex: urls = ["https://us-west-2-1.aws.cloud2.influxdata.com"]
#   urls = ["http://127.0.0.1:8086"]
#
#   ## Local address to bind when connecting to the server
#   ## If empty or not set, the local address is automatically chosen.
#   # local_address = ""
#
#   ## Token for authentication.
#   token = ""
#
#   ## Organization is the name of the organization you wish to write to.
#   organization = ""
#
#   ## Destination bucket to write into.
#   bucket = ""
#
#   ## The value of this tag will be used to determine the bucket.  If this
#   ## tag is not set the 'bucket' option is used as the default.
#   # bucket_tag = ""
#
#   ## If true, the bucket tag will not be added to the metric.
#   # exclude_bucket_tag = false
#
#   ## Timeout for HTTP messages.
#   # timeout = "5s"
#
#   ## Additional HTTP headers
#   # http_headers = {"X-Special-Header" = "Special-Value"}
#
#   ## HTTP Proxy override, if unset values the standard proxy environment
#   ## variables are consulted to determine which proxy, if any, should be used.
#   # http_proxy = "http://corporate.proxy:3128"
#
#   ## HTTP User-Agent
#   # user_agent = "telegraf"
#
#   ## Content-Encoding for write request body, can be set to "gzip" to
#   ## compress body or "identity" to apply no encoding.
#   # content_encoding = "gzip"
#
#   ## Enable or disable uint support for writing uints influxdb 2.0.
#   # influx_uint_support = false
#
#   ## When true, Telegraf will omit the timestamp on data to allow InfluxDB
#   ## to set the timestamp of the data during ingestion. This is generally NOT
#   ## what you want as it can lead to data points captured at different times
#   ## getting omitted due to similar data.
#   # influx_omit_timestamp = false
#
#   ## HTTP/2 Timeouts
#   ## The following values control the HTTP/2 client's timeouts. These settings
#   ## are generally not required unless a user is seeing issues with client
#   ## disconnects. If a user does see issues, then it is suggested to set these
#   ## values to "15s" for ping timeout and "30s" for read idle timeout and
#   ## retry.
#   ##
#   ## Note that the timer for read_idle_timeout begins at the end of the last
#   ## successful write and not at the beginning of the next write.
#   # ping_timeout = "0s"
#   # read_idle_timeout = "0s"
#
#   ## Optional TLS Config for use on HTTP connections.
#   # tls_ca = "/etc/telegraf/ca.pem"
#   # tls_cert = "/etc/telegraf/cert.pem"
#   # tls_key = "/etc/telegraf/key.pem"
#   ## Use TLS but skip chain & host verification
#   # insecure_skip_verify = false
